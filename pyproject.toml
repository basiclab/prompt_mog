[project]
name = "lpd_eval"
version = "0.1.0"
description = "Evaluation Toolkit for Long-Prompt-Diversity Benchmark (LPD-Bench)"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "accelerate>=1.12.0",
    "diffusers>=0.35.2",
    "einops>=0.8.1",
    "protobuf>=6.31.1",
    "sentencepiece>=0.2.0",
    "transformers>=4.57.3",
    "tyro>=0.9.35",
    "datasets>=4.4.1",
    "aesthetic-predictor-v2-5>=2024.12.18.1",
    "scipy>=1.16.3",
    "scikit-learn>=1.7.2",
]

[project.scripts]
lpd_print = "lpd_eval.__main__:cli_print"
lpd_eval = "lpd_eval.__main__:cli"

[tool.setuptools.packages.find]
include = ["lpd_eval*"]

